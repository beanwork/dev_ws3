{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## TF_IDF"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 한 문서에서 많이 등장한 단어에 가중치를 (term frquency)\n",
    "- 전체 문서에서 많이 나타나는 단어는 중요하지 않게..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### tfidfvectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from konlpy.tag import Twitter\n",
    "\n",
    "vectorizer = TfidfVectorizer(min_df=1, decode_error='ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/soomin/venv/nltk/lib/python3.10/site-packages/konlpy/tag/_okt.py:17: UserWarning: \"Twitter\" has changed to \"Okt\" since KoNLPy v0.4.5.\n",
      "  warn('\"Twitter\" has changed to \"Okt\" since KoNLPy v0.4.5.')\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[' 상처 받은 아이 들 은 너무 일찍 커버 려',\n",
       " ' 내 가 상처 받은 거 아는 사람 불편해',\n",
       " ' 잘 사는 사람 들 은 좋은 사람 되기 쉬워',\n",
       " ' 아무 일도 아니야 괜찮아']"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "contents = ['상처받은 아이들은 너무 일찍 커버려',\n",
    "            '내가 상처받은 거 아는 사람 불편해',\n",
    "            '잘 사는 사람들은 좋은 사람 되기 쉬워',\n",
    "            '아무 일도 아니야 괜찮아']\n",
    "\n",
    "t = Twitter()\n",
    "\n",
    "contents_token = []\n",
    "for row in contents:\n",
    "    contents_token.append(t.morphs(row))\n",
    "\n",
    "contents_for_vectorize = []\n",
    "\n",
    "for content in contents_token:\n",
    "    sentence = ''\n",
    "    for word in content:\n",
    "        sentence = sentence + ' ' + word\n",
    "\n",
    "    contents_for_vectorize.append(sentence)\n",
    "\n",
    "contents_for_vectorize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "vector = vectorizer.fit_transform(contents_for_vectorize)\n",
    "num_samples, num_features = vector.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 확인"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.        , 0.        , 0.        , 0.5       ],\n",
       "       [0.43671931, 0.        , 0.        , 0.        ],\n",
       "       [0.        , 0.        , 0.39264414, 0.        ],\n",
       "       [0.34431452, 0.40104275, 0.        , 0.        ],\n",
       "       [0.        , 0.50867187, 0.        , 0.        ],\n",
       "       [0.        , 0.        , 0.39264414, 0.        ],\n",
       "       [0.        , 0.40104275, 0.6191303 , 0.        ],\n",
       "       [0.34431452, 0.40104275, 0.        , 0.        ],\n",
       "       [0.        , 0.        , 0.39264414, 0.        ],\n",
       "       [0.        , 0.50867187, 0.        , 0.        ],\n",
       "       [0.        , 0.        , 0.        , 0.5       ],\n",
       "       [0.        , 0.        , 0.        , 0.5       ],\n",
       "       [0.43671931, 0.        , 0.        , 0.        ],\n",
       "       [0.        , 0.        , 0.        , 0.5       ],\n",
       "       [0.43671931, 0.        , 0.        , 0.        ],\n",
       "       [0.        , 0.        , 0.39264414, 0.        ],\n",
       "       [0.43671931, 0.        , 0.        , 0.        ]])"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vector.toarray().transpose()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 테스트 문장 적용"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.78528828, 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.6191303 , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        ]])"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new_post = ['상처받기 싫어 괜찮아']\n",
    "new_post_tokens = []\n",
    "\n",
    "for row in new_post:\n",
    "    new_post_tokens.append(t.morphs(row))\n",
    "\n",
    "new_post_for_vectorize = []\n",
    "\n",
    "for content in new_post_tokens:\n",
    "    sentence =''\n",
    "    for word in content:\n",
    "        sentence = sentence +' ' +word\n",
    "\n",
    "    new_post_for_vectorize.append(sentence)\n",
    "\n",
    "new_post_vec = vectorizer.transform(new_post_for_vectorize)\n",
    "new_post_vec.toarray()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 거리를 구하는 또다른 방법 normalize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import scipy as sp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def dist_norm(v1, v2):\n",
    "    v1_norm = v1 / sp.linalg.norm(v1.toarray())\n",
    "    v2_norm = v2 / sp.linalg.norm(v2.toarray())\n",
    "\n",
    "    delta = v1_norm - v2_norm\n",
    "    return sp.linalg.norm(delta.toarray())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[1.2544516324460193, 1.2261339938790283, 1.414213562373095, 1.1021396119773588]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dist = []\n",
    "\n",
    "for each in vector:\n",
    "    dist.append(dist_norm(each, new_post_vec))\n",
    "\n",
    "dist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "nltk",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
